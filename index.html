                  <!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title style="font-family:Comic Sans MS; font-size:48px">Lei Zhang</title>

    <meta name="author" content="Lei Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/zju_icon.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align:center;font-family:Comic Sans MS;font-size:32px">
                  Lei Zhang
                </p>
                <p>I am a master student(Sep.2021 -) student in the Software Engineering department at <a href="https://www.zju.edu.cn/english//">Zhejiang University</a>, focusing on multimodal large language models, AI alignment, and data-centric machine learning.  
                <p>
                  Currently, I'm a visiting researcher in <a href="https://www.ucsc.edu/">University of California, Santa Cruz</a> with Prof. <a href="https://cihangxie.github.io/"> Cihang Xie</a>. Before that, I spent great time at <a href="https://www.alibabagroup.com/en-US/">Alibaba Group</a> as a research intern. I'm so lucky to work with Prof. <a href="https://yuyinzhou.github.io/"> Yuyin Zhou</a> at <a href="https://www.ucsc.edu/">UCSC</a>, and Dr. <a href="https://zzutk.github.io/"> Zhifei Zhang</a> from <a href="https://research.adobe.com/">Adobe Research</a>.
                </p>
                <p>
                  My research interest lies in machine learning and its applications, especially:
		   <p style="line-height:0.6em;"> &nbsp;&#x2022;&nbsp;&nbsp; Multimodal large language models (MLLMs) </p>
		   <p style="line-height:0.6em;"> &nbsp;&#x2022;&nbsp;&nbsp; AI alignment </p>
		   <p style="line-height:0.6em;"> &nbsp;&#x2022;&nbsp;&nbsp; Data-centric Machine Learning </p>
                </p>
<!--                 <p>
                 <font color='#ff0000'><em> Currently, I'm actively looking for 2024 Ph.D. positions. </em></font>
                </p> -->
                <p style="text-align:center">
                  <a href="mailto:stonermaxzl@gmail.com">stonermaxzl [at] gmail.com</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=aqwyG_YAAAAJ&hl=zh-CN/">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/yusalei/">Github</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/llleizhang/">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%;">
                <a href="images/LeiL.jpg"><img style="width:100%;max-width:100%;" alt="profile photo" src="images/LeiL.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/news.png", style="width:32px;height:auto" /> &nbsp; News</h2>
		<hr />
                <p style="line-height:0.8em;"> [07/2023]&nbsp;&nbsp; One first-authored paper is accepted by ICCV 2023. </p>
                <p style="line-height:0.8em;"> [03/2023]&nbsp;&nbsp; One first-authored paper is accepted by CVPR 2023 (<font color="red">Highlight; 2.5% acceptance rate</font>).</p>
              </td>
            <tr>
          </tbody></table>
	  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/research.png", style="width:32px;height:auto;" /> &nbsp;Publications</h2>
		<hr />
                <p>
                 Papers are sorted by recency, * denotes equal contribution.
                </p>
            </tr>
          </tbody></table>

        <table style="width:100%;margin-top:-40px;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/reward.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2312.06726.pdf">
            <span class="papertitle">Compress & Align: Curating Image-Text Data with Human Knowledge</span>
          </a>
          <br>
          <strong>Lei Zhang</strong>,
          <a href="https://scholar.google.com/citations?user=8Fq3EFkAAAAJ&hl=zh-CN&oi=ao/">Fangxun Shu</a>,
          <a href="https://oliverrensu.github.io/">Sucheng Ren</a>,
          <a href="https://bzhao.me/">Bingchen Zhao</a>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=0TvdOEcAAAAJ/">Hao Jiang</a>,
          <a href="https://cihangxie.github.io/">Cihang Xie</a>
          <br>
          <em>Preprint</em>, 2023 
          <br>
          <a href="https://arxiv.org/pdf/2312.06726">ArXiv</a>
          /
	  <a href="bibtex/zhang2023compress.txt">BibTeX</a>
          <p></p>
          <p>
          The first one introduces a human-knowledge-based algorithm to address the alignment and efficiency of large-scale image-text data. It can secure model performance by compressing the image-text datasets up tp ~90%.
          </p>
        </td>
      </tr>
		
        <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/mllm.png' width=250>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2312.06720.pdf">
            <span class="papertitle">Audio-Visual LLM for Video Understanding</span>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=8Fq3EFkAAAAJ&hl=zh-CN&oi=ao/">Fangxun Shu*</a>,
          <strong>Lei Zhang*</strong>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=0TvdOEcAAAAJ/">Hao Jiang</a>,
          <a href="https://cihangxie.github.io/">Cihang Xie</a>
          <br>
          <em>Preprint</em>, 2023 
          <br>
          <a href="https://arxiv.org/pdf/2312.06720">ArXiv</a>
          /
          <a href="bibtex/zhang2023audio.txt">BibTeX</a>
          <p></p>
          <p>
          Develop Aduio-Visual LLM, which take both visual and audio inputs for holistic video understanding and reasoning. Two key designs: modality-augmented training and GPT-4 assisted instruction generation. It attains super strong performance in understanding and reasoning tasks.
          </p>
        </td>
      </tr>
      
      
      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/fair.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf">
            <span class="papertitle">Towards Fairness-aware Adversarial Network Pruning</span>
          </a>
          <br>
  <strong>Lei Zhang</strong>, <a href="https://scholar.google.com/citations?user=0ox7zDkAAAAJ&hl=zh-CN&oi=ao">Zhibo Wang</a>, <a href="https://scholar.google.com/citations?user=F3uZ_gEAAAAJ&hl=zh-CN&oi=ao">Xiaowei Dong</a>, <a href="https://yunhefeng.me/">Yunhe Feng</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=wWCZSVMAAAAJ">Xiaoyi Pang</a>, <a href="https://zzutk.github.io/">Zhifei Zhang</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=uuQA_rcAAAAJ">Kui Ren</a> 
          <br>
          <em>ICCV</em>, 2023
          <br>
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf">ArXiv</a> / 
          <a href="bibtex/zhang2023ICCV.txt">BibTeX</a>
          <p></p>
          <p>Propose a adversarial fairness-aware network pruning method, which optimizes both pruning and debias tasks jointly by adversarial training. It significantly improves fairness by around 50% as compared to traditional pruning methods.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/ddistillation.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Accelerating_Dataset_Distillation_via_Model_Augmentation_CVPR_2023_paper.pdf">
            <span class="papertitle">Accelerate Dataset Distillation via Model Augmentation</span>
          </a>
          <br>
	  <strong>Lei Zhang</strong>,
          <a href="https://zj-jayzhang.github.io/">Jie Zhang</a>,
          <a href="https://stevenboys.github.io/">Bowen Lei</a>,
          <a href="https://scholar.google.de/citations?user=T4iBN5cAAAAJ&hl=en">Subhabrata Mukherjee</a>,  
          <a href="https://xiangpan.info/">Xiang Pan</a>,
          <a href="https://www.bozhao.me/">Bo Zhao</a>,
          <a href="https://caiwending.cse.uconn.edu/">Caiwen Ding</a>,
          <a href="https://liyao880.github.io/yaoli/">Yao Li</a>,
          <a href="https://dongkuanx27.github.io/">Dongkuan Xu</a>
          <br>
          <em>CVPR</em>, 2023 <font color="red"><strong>(Highlight)</strong></font>
          <br>
          <a href="https://arxiv.org/abs/2212.06152">ArXiv</a> /
          <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_Accelerating_Dataset_Distillation_CVPR_2023_supplemental.pdf">Supplementary Material</a> /
          <a href="https://github.com/ncsu-dk-lab/Acc-DD">Code</a> /
          <a href="bibtex/zhang2023CVPR.txt">BibTeX</a>
          <p></p>
          <p>
          Propose two model augmentation techniques, i.e., using early-stage models and weight perturbation to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20× speedup and comparable performance on par with state-of-the-art baseline methods.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/black.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.pdf">
            <span class="papertitle">Towards Efficient Data Free Black-Box Adversarial Attack</span>
          </a>
          <br>
          <a href="https://zj-jayzhang.github.io/">Jie Zhang</a>,
          <a href="https://scholar.google.co.jp/citations?hl=zh-CN&user=NVzQ87sAAAAJ&view_op=list_works&sortby=pubdate">Bo Li</a>,
          <a href="https://scholar.google.com/citations?user=bkYGs40AAAAJ&hl=zh-CN">Jianghe Xu</a>,
          <a href="https://scholar.google.com.hk/citations?user=_MtBmxkAAAAJ&hl=zh-CN">Shuang Wu</a>,
          <a href="https://scholar.google.com/citations?user=OGf40fkAAAAJ&hl=en">Shouhong Ding</a>,
          <strong>Lei Zhang</strong>,
          <a href="https://scholar.google.co.uk/citations?hl=en&user=gpTPt58AAAAJ&view_op=list_works&sortby=pubdate">Chao Wu</a>,
          <br>
          <em>CVPR</em>, 2022
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.pdf">ArXiv</a> /
          <a href="https://github.com/zj-jayzhang/Data-Free-Transfer-Attack">Code</a> /
          <a href="bibtex/zhang2022CVPR.txt">BibTeX</a>
          <p></p>
          <p>
          By rethinking the collaborative relationship between the generator and the substitute model, we design a novel black-box attack framework. The proposed method can efficiently imitate the target model through a small number of queries and achieve high attack success rate.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/gae.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/document/9897634">
            <span class="papertitle">Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning</span>
          </a>
          <br>
          <a href="https://zj-jayzhang.github.io/">Jie Zhang*</a>,
          <strong>Lei Zhang*</strong>,
          <a href="https://ieeexplore.ieee.org/author/37089720515/">Gang Li</a>,
          <a href="https://scholar.google.co.uk/citations?hl=en&user=gpTPt58AAAAJ&view_op=list_works&sortby=pubdate">Chao Wu</a>
          <br>
          <em>ICIP</em>, 2022
          <br>
          <a href="https://arxiv.org/abs/2201.12356">ArXiv</a> /
          <a href="bibtex/zhang2022ICIP.txt">BibTeX</a>
          <p></p>
          <p>
            Provide a new perspective on how to deal with imbalanced data: adjust the biased decision boundary by training with Guiding Adversarial Examples (GAEs).
          </p>
        </td>
      </tr>
            
      </tbody></table>

	
      <table style="width:100%;border:0px;padding-top:20px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
        <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/experience2.png", style="width:32px;height:auto;" /> &nbsp;Experiences</h2>
	<hr />
	</td>
	</tr>    
	</tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr> <td style="padding-left:23px;width:15%;vertical-align:center;"> 
	<img src='icons/ucsc.png' style="width:85px;height:auto;" /> 
	</td> <td style="padding-left:0px;width:85%;vertical-align:left;line-height:150%;text-align:left;"> 
        <a href="https://www.ucsc.edu/"> <span class="papertitle">University of California, Santa Cruz</span> 
	</a> <br> <strong>Visiting Student, Mar 2023 - Present</strong> <br>
        <em>Supervised by Prof. <a href="https://cihangxie.github.io/"> Cihang Xie</a>, work on multimodal alignment and large-scale training of vision-language models.</em> 
	</td></tr>
		
        <tr> <td style="padding-left:15px;width:15%;vertical-align:center;"> 
	<img src='icons/alibaba2.png' style="width:115px;height:auto;" /> 
	</td> <td style="padding:0px;width:85%;vertical-align:left;line-height:150%;text-align:left;"> 
        <a href="https://www.alibabagroup.com/en-US/"> <span class="papertitle">Alibaba Group</span> 
	</a> <br> <strong>Research Intern, May 2023 - Dec 2023</strong> <br>
        <em>Work on Multimodal large language models (MLLMs).</em> 
	</td></tr> 

	<tr> <td style="padding-left:14px;width:15%;vertical-align:center;border:30px;"> <img src='icons/Microsoft_Research_Asia_logo.png' style="object-fit:scale-down;width:100px;height:120px" /> 
	</td> <td style="padding:0px;width:85%;vertical-align:left;line-height:150%;text-align:left;"> 
	<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"> 
	<span class="papertitle">Microsoft Research Asia</span> </a> <br> <strong>Researcher Intern, Dec 2022 - Feb 2023</strong> 
	<br> <em>Supervised by Dr. <a href="https://scholar.google.com/citations?user=Ow4R8-EAAAAJ&hl=en"> Xun Guo</a> work on text-to-3d diffusion model.</em> 
	</td> </tr> 

	</td>
	</tr>    
	</tbody></table>

<!--          <table style="width:100%;padding-top:70px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/award2.png", style="width:32px;height:auto;" /> &nbsp; Selected Honors and Awards</h2>
		<hr />
                <p style="font-size:20px"> <li> Stars of Tomorrow (Microsoft Research Asia) </li> </p>
		<p style="line-height:0.4em;font-size:20px"> <li> CVPR AMFG 2021 Best Paper Award </li> </p>
		<p style="line-height:0.4em;font-size:20px"> <li> Beihang University Excellent Graduate </li> </p>
              </td>
            </tr>
          </tbody></table> -->
		
         <table style="width:100%;padding-top:30px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/activity.png", style="width:32px;height:auto;" /> &nbsp; Professional Services</h2>
		<hr />
                <p style="line-height:0.8em;font-size:14px;"> <em> Conference Reviewer: CVPR 2024, NIPS 2024, CVPR 2023 </em> </p>
		<p style="line-height:0.8em;font-size:14px;"> <em> Journal Reviewer: IEEE TPAMI </em> </p>
              </td>
            </tr>
          </tbody></table>
	  
<!--          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
	      <td style="padding:20px;width:100%;vertical-align:middle">
		<a href="https://clustrmaps.com/site/1bwxo" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=LpeUFK6E0UqKyMayHxJ376iYqiMie7Njj0rKOZhMZhE" /></a>
              </td>
            </tr>
          </tbody></table> -->
	  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px">
                <br>
                <p style="text-align:right;font-size:small;">
                  No web trackers, feel free to see this website&#12288;&#12288;&#12288;&#12288;&#12288;&#12288; Last Update: 01/2024  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  <a href="https://jonbarron.info/">Template</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          
  </body>
</html>
