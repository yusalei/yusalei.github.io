                  <!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title style="font-family:Comic Sans MS; font-size:48px">Lei Zhang</title>

    <meta name="author" content="Lei Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/zju_icon.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align:center;font-family:Comic Sans MS;font-size:32px">
                  Lei Zhang
                </p>
                <p>I am a master student(Sep.2021 -) student in the Software Engineering department at <a href="https://www.zju.edu.cn/english//">Zhejiang University</a>, focusing on multimodal large language models, AI alignment, and data-centric machine learning.  
                <p>
                  Currently, I'm a visiting researcher in <a href="https://www.ucsc.edu/">University of California, Santa Cruz</a> with Prof. <a href="https://cihangxie.github.io/"> Cihang Xie</a>. Before that, I spent great time at <a href="https://www.alibabagroup.com/en-US/">Alibaba Group</a> as a research intern. I'm so lucky to work with Prof. <a href="https://yuyinzhou.github.io/"> Yuyin Zhou</a> at <a href="https://www.ucsc.edu/">UCSC</a>, and Dr. <a href="https://zzutk.github.io/"> Zhifei Zhang</a> from <a href="https://research.adobe.com/">Adobe Research</a>.
                </p>
                <p>
                  My research interest lies in machine learning and its applications, especially:
		   <p style="line-height:0.6em;"> &nbsp;&#x2022;&nbsp;&nbsp; Multimodal large language models (MLLMs) </p>
		   <p style="line-height:0.6em;"> &nbsp;&#x2022;&nbsp;&nbsp; AI alignment </p>
		   <p style="line-height:0.6em;"> &nbsp;&#x2022;&nbsp;&nbsp; Data-centric Machine Learning </p>
                </p>
<!--                 <p>
                 <font color='#ff0000'><em> Currently, I'm actively looking for 2024 Ph.D. positions. </em></font>
                </p> -->
                <p style="text-align:center">
                  <a href="mailto:stonermaxzl@gmail.com">stonermaxzl [at] gmail.com</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=aqwyG_YAAAAJ&hl=zh-CN/">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/yusalei/">Github</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/llleizhang/">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%;">
                <a href="images/LeiL.jpg"><img style="width:100%;max-width:100%;" alt="profile photo" src="images/LeiL.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/news.png", style="width:32px;height:auto" /> &nbsp; News</h2>
		<hr />
                <p style="line-height:0.8em;"> [07/2023]&nbsp;&nbsp; One first-authored paper is accepted by ICCV 2023. </p>
                <p style="line-height:0.8em;"> [03/2023]&nbsp;&nbsp; One first-authored paper is accepted by CVPR 2023 (<font color="red">Highlight; 2.5% acceptance rate</font>).</p>
              </td>
            <tr>
          </tbody></table>
	  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/research.png", style="width:32px;height:auto;" /> &nbsp;Publications</h2>
		<hr />
                <p>
                 Papers are sorted by recency, * denotes equal contribution.
                </p>
            </tr>
          </tbody></table>

        <table style="width:100%;margin-top:-40px;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/reward.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2312.06726.pdf">
            <span class="papertitle">Compress & Align: Curating Image-Text Data with Human Knowledge</span>
          </a>
          <br>
          <strong>Lei Zhang</strong>,
          <a href="https://scholar.google.com/citations?user=8Fq3EFkAAAAJ&hl=zh-CN&oi=ao/">Fangxun Shu</a>,
          <a href="https://oliverrensu.github.io/">Sucheng Ren</a>,
          <a href="https://bzhao.me/">Bingchen Zhao</a>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=0TvdOEcAAAAJ/">Hao Jiang</a>,
          <a href="https://cihangxie.github.io/">Cihang Xie</a>
          <br>
          <em>Preprint</em>, 2023 
          <br>
          <a href="https://arxiv.org/pdf/2312.06726">ArXiv</a>
          /
	  <a href="bibtex/zhang2023compress.txt">BibTeX</a>
          <p></p>
          <p>
          The first one introduces a human-knowledge-based algorithm to address the alignment and efficiency of large-scale image-text data. It can secure model performance by compressing the image-text datasets up tp ~90%.
          </p>
        </td>
      </tr>
		
        <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/mllm.png' width=250>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2312.06720.pdf">
            <span class="papertitle">Audio-Visual LLM for Video Understanding</span>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=8Fq3EFkAAAAJ&hl=zh-CN&oi=ao/">Fangxun Shu*</a>,
          <strong>Lei Zhang*</strong>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=0TvdOEcAAAAJ/">Hao Jiang</a>,
          <a href="https://cihangxie.github.io/">Cihang Xie</a>
          <br>
          <em>Preprint</em>, 2023 
          <br>
          <a href="https://arxiv.org/pdf/2312.06720">ArXiv</a>
          /
          <a href="bibtex/zhang2023audio.txt">BibTeX</a>
          <p></p>
          <p>
          Develop Aduio-Visual LLM, which take both visual and audio inputs for holistic video understanding and reasoning. Two key designs: modality-augmented training and GPT-4 assisted instruction generation. It attains super strong performance in understanding and reasoning tasks.
          </p>
        </td>
      </tr>
      
      
      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/fair.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf">
            <span class="papertitle">Towards Fairness-aware Adversarial Network Pruning</span>
          </a>
          <br>
  <strong>Lei Zhang</strong>, <a href="https://scholar.google.com/citations?user=0ox7zDkAAAAJ&hl=zh-CN&oi=ao">Zhibo Wang</a>, <a href="https://scholar.google.com/citations?user=F3uZ_gEAAAAJ&hl=zh-CN&oi=ao">Xiaowei Dong</a>, <a href="https://yunhefeng.me/">Yunhe Feng</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=wWCZSVMAAAAJ">Xiaoyi Pang</a>, <a href="https://zzutk.github.io/">Zhifei Zhang</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=uuQA_rcAAAAJ">Kui Ren</a> 
          <br>
          <em>ICCV</em>, 2023
          <br>
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf">ArXiv</a> / 
          <a href="bibtex/zhang2023ICCV.txt">BibTeX</a>
          <p></p>
          <p>Propose a adversarial fairness-aware network pruning method, which optimizes both pruning and debias tasks jointly by adversarial training. It significantly improves fairness by around 50% as compared to traditional pruning methods.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/ddistillation.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Accelerating_Dataset_Distillation_via_Model_Augmentation_CVPR_2023_paper.pdf">
            <span class="papertitle">Accelerate Dataset Distillation via Model Augmentation</span>
          </a>
          <br>
	  <strong>Lei Zhang</strong>,
          <a href="https://zj-jayzhang.github.io/">Jie Zhang</a>,
          <a href="https://stevenboys.github.io/">Bowen Lei</a>,
          <a href="https://scholar.google.de/citations?user=T4iBN5cAAAAJ&hl=en">Subhabrata Mukherjee</a>,  
          <a href="https://xiangpan.info/">Xiang Pan</a>,
          <a href="https://www.bozhao.me/">Bo Zhao</a>,
          <a href="https://caiwending.cse.uconn.edu/">Caiwen Ding</a>,
          <a href="https://liyao880.github.io/yaoli/">Yao Li</a>,
          <a href="https://dongkuanx27.github.io/">Dongkuan Xu</a>
          <br>
          <em>CVPR</em>, 2023 <font color="red"><strong>(Highlight)</strong></font>
          <br>
          <a href="https://arxiv.org/abs/2212.06152">ArXiv</a> /
          <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_Accelerating_Dataset_Distillation_CVPR_2023_supplemental.pdf">Supplementary Material</a> /
          <a href="https://github.com/ncsu-dk-lab/Acc-DD">Code</a> /
          <a href="bibtex/zhang2023CVPR.txt">BibTeX</a>
          <p></p>
          <p>
          Propose two model augmentation techniques, i.e., using early-stage models and weight perturbation to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20Ã— speedup and comparable performance on par with state-of-the-art baseline methods.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/black.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.pdf">
            <span class="papertitle">Towards Efficient Data Free Black-Box Adversarial Attack</span>
          </a>
          <br>
          <a href="https://zj-jayzhang.github.io/">Jie Zhang</a>,
          <a href="https://scholar.google.co.jp/citations?hl=zh-CN&user=NVzQ87sAAAAJ&view_op=list_works&sortby=pubdate">Bo Li</a>,
          <a href="https://scholar.google.com/citations?user=bkYGs40AAAAJ&hl=zh-CN">Jianghe Xu</a>,
          <a href="https://scholar.google.com.hk/citations?user=_MtBmxkAAAAJ&hl=zh-CN">Shuang Wu</a>,
          <a href="https://scholar.google.com/citations?user=OGf40fkAAAAJ&hl=en">Shouhong Ding</a>,
          <strong>Lei Zhang</strong>,
          <a href="https://scholar.google.co.uk/citations?hl=en&user=gpTPt58AAAAJ&view_op=list_works&sortby=pubdate">Chao Wu</a>,
          <br>
          <em>CVPR</em>, 2022
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.pdf">ArXiv</a> /
          <a href="https://github.com/zj-jayzhang/Data-Free-Transfer-Attack">Code</a> /
          <a href="bibtex/zhang2022CVPR.txt">BibTeX</a>
          <p></p>
          <p>
          By rethinking the collaborative relationship between the generator and the substitute model, we design a novel black-box attack framework. The proposed method can efficiently imitate the target model through a small number of queries and achieve high attack success rate.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/gae.png' width="250">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/document/9897634">
            <span class="papertitle">Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning</span>
          </a>
          <br>
          <a href="https://zj-jayzhang.github.io/">Jie Zhang*</a>,
          <strong>Lei Zhang*</strong>,
          <a href="https://ieeexplore.ieee.org/author/37089720515/">Gang Li</a>,
          <a href="https://scholar.google.co.uk/citations?hl=en&user=gpTPt58AAAAJ&view_op=list_works&sortby=pubdate">Chao Wu</a>
          <br>
          <em>ICIP</em>, 2022
          <br>
          <a href="https://arxiv.org/abs/2201.12356">ArXiv</a> /
          <a href="bibtex/zhang2022ICIP.txt">BibTeX</a>
          <p></p>
          <p>
            Provide a new perspective on how to deal with imbalanced data: adjust the biased decision boundary by training with Guiding Adversarial Examples (GAEs).
          </p>
        </td>
      </tr>
            
      </tbody></table>

	
      <table style="width:100%;border:0px;padding-top:20px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
        <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/experience2.png", style="width:32px;height:auto;" /> &nbsp;Experiences</h2>
	<hr />
	</td>
	</tr>    
	</tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr> <td style="padding-left:23px;width:15%;vertical-align:center;"> 
	<img src='icons/ucsc.png' style="width:85px;height:auto;" /> 
	</td> <td style="padding-left:0px;width:85%;vertical-align:left;line-height:150%;text-align:left;"> 
        <a href="https://www.ucsc.edu/"> <span class="papertitle">University of California, Santa Cruz</span> 
	</a> <br> <strong>Visiting Student, Mar 2023 - Present</strong> <br>
        <em>Supervised by Prof. <a href="https://cihangxie.github.io/"> Cihang Xie</a>, work on multimodal alignment and large-scale training of vision-language models.</em> 
	</td></tr>
		
        <tr> <td style="padding-left:15px;width:15%;vertical-align:center;"> 
	<img src='icons/alibaba2.png' style="width:115px;height:auto;" /> 
	</td> <td style="padding:0px;width:85%;vertical-align:left;line-height:150%;text-align:left;"> 
        <a href="https://www.alibabagroup.com/en-US/"> <span class="papertitle">Alibaba Group</span> 
	</a> <br> <strong>Research Intern, May 2023 - Dec 2023</strong> <br>
        <em>Work on Multimodal large language models (MLLMs).</em> 
	</td></tr> 

	<tr> <td style="padding-left:14px;width:15%;vertical-align:center;border:30px;"> <img src='icons/Microsoft_Research_Asia_logo.png' style="object-fit:scale-down;width:100px;height:120px" /> 
	</td> <td style="padding:0px;width:85%;vertical-align:left;line-height:150%;text-align:left;"> 
	<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"> 
	<span class="papertitle">Microsoft Research Asia</span> </a> <br> <strong>Researcher Intern, Dec 2022 - Feb 2023</strong> 
	<br> <em>Supervised by Dr. <a href="https://scholar.google.com/citations?user=Ow4R8-EAAAAJ&hl=en"> Xun Guo</a> work on text-to-3d diffusion model.</em> 
	</td> </tr> 

	</td>
	</tr>    
	</tbody></table>

<!--          <table style="width:100%;padding-top:70px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/award2.png", style="width:32px;height:auto;" /> &nbsp; Selected Honors and Awards</h2>
		<hr />
                <p style="font-size:20px"> <li> Stars of Tomorrow (Microsoft Research Asia) </li> </p>
		<p style="line-height:0.4em;font-size:20px"> <li> CVPR AMFG 2021 Best Paper Award </li> </p>
		<p style="line-height:0.4em;font-size:20px"> <li> Beihang University Excellent Graduate </li> </p>
              </td>
            </tr>
          </tbody></table> -->
		
         <table style="width:100%;padding-top:30px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-family:Impact; font-size:24px; font-weight:bold"><img src="icons/activity.png", style="width:32px;height:auto;" /> &nbsp; Professional Services</h2>
		<hr />
                <p style="line-height:0.8em;font-size:14px;"> <em> Conference Reviewer: CVPR 2024, NIPS 2024, CVPR 2023 </em> </p>
		<p style="line-height:0.8em;font-size:14px;"> <em> Journal Reviewer: IEEE TPAMI </em> </p>
              </td>
            </tr>
          </tbody></table>
	  
<!--          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
	      <td style="padding:20px;width:100%;vertical-align:middle">
		<a href="https://clustrmaps.com/site/1bwxo" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=LpeUFK6E0UqKyMayHxJ376iYqiMie7Njj0rKOZhMZhE" /></a>
              </td>
            </tr>
          </tbody></table> -->
	  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px">
                <br>
                <p style="text-align:right;font-size:small;">
                  No web trackers, feel free to see this website&#12288;&#12288;&#12288;&#12288;&#12288;&#12288; Last Update: 01/2024  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  <a href="https://jonbarron.info/">Template</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          
  </body>
</html>
